{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "robot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXnk-KGIictu"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJFKomMHsJnt"
      },
      "source": [
        "!ls \"/content/drive\"\r\n",
        "!pip install ijson"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA8JEudMrnLY"
      },
      "source": [
        "# 環境初始化 (大約三至五分鐘)\n",
        "! wget -O init_env.sh https://www.dropbox.com/s/6bnwn8u2hz19s59/init_env.sh && \\\n",
        "bash init_env.sh\n",
        "\n",
        "!which python\n",
        "!/usr/local/bin/python -V\n",
        "\n",
        "import os, sys\n",
        "os.environ['SPARK_HOME'] = \"/usr/local/spark\"\n",
        "# os.environ['PYSPARK_PYTHON'] = \"/usr/bin/python\"\n",
        "os.environ['PYSPARK_PYTHON'] = \"/usr/local/bin/python\"\n",
        "sys.path.append(\"/usr/local/spark/python/\")\n",
        "sys.path.append(\"/usr/local/spark/python/lib/pyspark.zip\")\n",
        "sys.path.append(\"/usr/local/spark/python/lib/py4j-0.10.4-src.zip\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjFt83u5i7zh"
      },
      "source": [
        "################## spark declare #######################\r\n",
        "from pyspark import SparkContext\r\n",
        "from pyspark import SparkConf\r\n",
        "\r\n",
        "#sc.stop()\r\n",
        "sc = SparkContext()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMk384t5iljv"
      },
      "source": [
        "import ijson\n",
        "import re\n",
        "import os, sys\n",
        "\n",
        "f = open(\"/content/drive/My Drive/jsonJieba-tran/jsonJieba-tran.json\", mode = 'r', encoding='UTF-8')\n",
        "objects = ijson.items(f, 'item')\n",
        "num = 0\n",
        "\n",
        "####################### Handle json ###############################\n",
        "# Extract noun. plus wiki_index -> Word:Wiki_Index\n",
        "\n",
        "for p, article in enumerate(list(objects)):\n",
        "    # print(article[\"id\"], \\\n",
        "    # article[\"title\"], \\\n",
        "    # article[\"content\"])\n",
        "\n",
        "    if (p % 1000 == 0):\n",
        "        num = int(p / 1000)\n",
        "        os.makedirs(\"./test/TEST\" + str(num) + \"/\")\n",
        "\n",
        "    with open(\"./test/TEST\" + str(num) + \"/\" + str(article[\"id\"]) + \".txt\", mode = 'w', encoding='UTF-8') as f:\n",
        "        w_list = article[\"content\"].split(\"/\")\n",
        "        id_ = str(article[\"id\"])\n",
        "        word = []\n",
        "\n",
        "        for m, i in enumerate(w_list):\n",
        "          if (i != \"\"):\n",
        "            type_ = i.split()\n",
        "\n",
        "            for j, k in enumerate(type_):                \n",
        "              if (j > 0 and k.find(\"n\") >= 0):\n",
        "                  word.append(type_[0] + \":\" + id_)\n",
        "\n",
        "        str1 = \" \".join(word)\n",
        "        f.write(str1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86DiktZqszGU"
      },
      "source": [
        "####################### Merge word #############################\n",
        "# Use spark to merge the same word and different wiki_index\n",
        "# e.g. word wiki_index:wiki_count(apple 113333:2 333333:4)\n",
        "\n",
        "def test_(x):\n",
        "\n",
        "  temp = str(x[0])\n",
        "  name, id = temp.split(\":\")\n",
        "  freq = id + \":\" + str(x[1])\n",
        "\n",
        "  return (name, freq)\n",
        "\n",
        "filepath = './In_Index'\n",
        "\n",
        "if (not os.path.exists(filepath)):\n",
        "  os.mkdir(filepath)\n",
        "\n",
        "\n",
        "for a in (os.listdir(\"./test\")):\n",
        "\n",
        "  data_file = \"./test/\" + a + \"/\"\n",
        "  text_file = sc.textFile(data_file)\n",
        "\n",
        "  counts = text_file.flatMap(lambda line: line.split()) \\\n",
        "              .map(lambda word: (word, 1)) \\\n",
        "              .reduceByKey(lambda a, b: a + b) \\\n",
        "              .map(test_) \\\n",
        "              .reduceByKey(lambda a, b: a + \" \" + b) \\\n",
        "              .sortBy(lambda x: x[0], ascending=True) \\\n",
        "              .collect()\n",
        "\n",
        "  with open(\"./In_Index/\" + a + \".txt\", mode='w', encoding=\"UTF-8\") as f:   \n",
        "    for i in counts:\n",
        "      f.write(i[0] + \"\\t\" + i[1] + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ9RgxowGfVv"
      },
      "source": [
        "################## Merge parts of In_Index ########################\n",
        "# Merge part to become one Inverted_Index\n",
        "# Use Inverted_Index to answer the ques\n",
        "\n",
        "data_file = \"./In_Index\"\n",
        "\n",
        "text_file = sc.textFile(data_file)\n",
        "wordcountsRDD = text_file.map(lambda line: line.split(\"\\t\", 1)) \\\n",
        "             .reduceByKey(lambda a, b: a + \" \" + b) \\\n",
        "             .sortBy(lambda x: x[0], ascending = False) \\\n",
        "             .collect()\n",
        "\n",
        "with open(\"./Inverted_Index\", mode='w', encoding=\"UTF-8\") as f:\n",
        "  for i in wordcountsRDD:    \n",
        "    f.write(i[0] + \"\\t\" + i[1] + \"\\n\")"
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}